---
title: "Iteration and Listcols"
output: github_document
---
this is the repository for iteration part 2 of P8105

```{r setup}
library(tidyverse)
library(rvest)

set.seed(1)

```

## Lists 
```{r}
l = list(
  vec_numeric = 1:4,
  unif_sample = runif(100),
  mat = matrix(1:8, nrow = 2, ncol=4, byrow = TRUE),
  summary = summary(rnorm(1000))
)

l

l[["mat"]] [1,3]
l[[4]]
```

Make a list that is more useful
```{r}
list_norm =
  list(
    a = rnorm(20,0,5),
    b = rnorm(20,4,5),
    c = rnorm(20,0,10),
    d = rnorm(20,4,10)
  )
list_norm[["b"]]
```

Lets re use function used last time
```{r}
mean_and_sd = function(x) {
  
  if (!is.numeric(x)) {
    stop("Argument x should be numeric")
  } else if (length(x) == 1) {
    stop("Cannot be computed for length 1 vectors")
  }
  
  mean_x = mean(x)
  sd_x = sd(x)

  tibble(
    mean = mean_x, 
    sd = sd_x
  )
}
```

Lets use the function to take mean and sd of all samples 
```{r}
mean_and_sd(list_norm[["a"]])
mean_and_sd(list_norm[["b"]])
mean_and_sd(list_norm[["c"]])
mean_and_sd(list_norm[["d"]])
```

## Use a for loop
```{r}
output = vector('list', length =4)

for(i in 1:4){
  output[[i]]=mean_and_sd(list_norm[[i]])
}

output
```

## Do the same thing with map
```{r}
output = map(list_norm, mean_and_sd)
```

```{r}
output = map_dbl(list_norm, IQR)
```

```{r}
output = map_dfr(list_norm, mean_and_sd, .id = "input")

output
```


##List columns

```{r}
listcol_df = 
  tibble(
    name = c("a", "b", "c", "d"),
    samp = list_norm
  )
```

```{r}
listcol_df |> pull(name)
```

```{r}
listcol_df |> pull(samp)
```

```{r}
map(listcol_df$samp, mean_and_sd)
```

```{r}
listcol_df = 
  listcol_df |> 
  mutate(summary = map(samp, mean_and_sd))

listcol_df
```

## NSDUH
```{r}
nsduh_table <- function(html, table_num) {
  
  table = 
    html |> 
    html_table() |> 
    nth(table_num) |>
    slice(-1) |> 
    select(-contains("P Value")) |>
    pivot_longer(
      -State,
      names_to = "age_year", 
      values_to = "percent") |>
    separate(age_year, into = c("age", "year"), sep = "\\(") |>
    mutate(
      year = str_replace(year, "\\)", ""),
      percent = str_replace(percent, "[a-c]$", ""),
      percent = as.numeric(percent)) |>
    filter(!(State %in% c("Total U.S.", "Northeast", "Midwest", "South", "West")))
  
  table
}

```

```{r}
nsduh_url = "http://samhda.s3-us-gov-west-1.amazonaws.com/s3fs-public/field-uploads/2k15StateFiles/NSDUHsaeShortTermCHG2015.htm"

nsduh_html = read_html(nsduh_url)

output = vector("list", 3)

for (i in c(1, 4, 5)) {
  output[[i]] = nsduh_table(nsduh_html, i)
}

nsduh_results = bind_rows(output)
```

```{r}
nsduh_results = 
  map(c(1, 4, 5), nsduh_table, html = nsduh_html) |> 
  bind_rows()
```

```{r}
nsduh_results= 
  tibble(
    name = c("marj", "cocaine", "heroine"),
    number = c(1, 4, 5)) |> 
  mutate(table = map(number, \(num) nsduh_table(html = nsduh_html, num))) |> 
  unnest(cols = "table")

```


## Weather data
```{r}
weather_df = 
  rnoaa::meteo_pull_monitors(
    c("USW00094728", "USW00022534", "USS0023B17S"),
    var = c("PRCP", "TMIN", "TMAX"), 
    date_min = "2021-01-01",
    date_max = "2022-12-31") |>
  mutate(
    name = recode(
      id, 
      USW00094728 = "CentralPark_NY", 
      USW00022534 = "Molokai_HI",
      USS0023B17S = "Waterhole_WA"),
    tmin = tmin / 10,
    tmax = tmax / 10) |>
  select(name, id, everything())
```

```{r}
weather_nest = 
  nest(weather_df, data = date:tmin)

weather_nest
```

```{r}
weather_nest |> pull(name)
```

```{r}
weather_nest |> pull(data)
```

